\section{Сравнение алгоритмов многомерной минимизации}
Алгоритм многомерной минимизации должен отвечать следующим критериям:
\begin{enumerate}
    \item Метод работает для широкого спектра функций. Универсальность метода.
    \item Число необходимых вычислений целевой функции чем меньше тем лучше. Например вычисление одной производной требует 2 вычисления значения функции в разных точках, а второй производной целых 3 значения.
    \item Чем меньше количество итераций для достижения минимума с определенной точностью, тем лучше.
\end{enumerate}

Классическая тестовая задача для проверки алгоритмов многомерной минимизации - функция Розенброка (рис. \ref{fig:Rosenbrock}):
\begin{equation*}
    f(\vec x) = 100 (x_2 - x_1^2)^2 +(1-x_1)^2
\end{equation*}
Известно, что:
\begin{equation}
    \vec x_{min} = \left[\begin{array}{cc}
        1 \\
        1 
    \end{array}\right]\text{;} \qquad f(x_{min}) = 0
\end{equation}
\begin{figure}
    \centering
    \includegraphics[scale = 0.7]{Pictures/Rosenbrock.png}
    \caption{Функция Розенброка в трехмерном виде}
    \label{fig:Rosenbrock}
\end{figure}
\textit{По аналитическому виду функции можно заметить, что масштаб осей не соразмерен, о чем мы говорили разделе \ref{GradientMethod}}
%Надо изобразить функцию Розенброка

Посмотрим как справятся изученные нами методы с этой функцией (рис. \ref{fig:Rosenbrock_levels}):
\begin{figure}
    \centering
    \includegraphics[scale = 0.5]{Pictures/Rosenbrock_levels.png}
    \caption{Линия уровней функции Розенброка. Иллюстрация к сравнению методов.}
    \label{fig:Rosenbrock_levels}
\end{figure}
\begin{enumerate}
    \item Для метода антиградиента может не выйти найти минимум такой функции. Это зависит от первой точки, которая будет выбрана. Минимума мы можем не достичь поскольку первым шагом мы попадем на <<дно>>, где функция уже мало меняется, и не выполняются критерии продолжения алгоритма. Попасть в минимум сможем только если первое направление пройдет через точку минимума непосредственно. Эта ситуация показывает нам еще один критерий сравнения, а именно независимость от точки старта.
    \item Для метода Ньютона на первом же шаге направление будет отличаться от направления первого шага метода антиградиента, поскольку вторая производная дает методу <<зрение>>. Метод хорошо справляется с тестовой функцией.
    \item Очевидно, что метод Дэвидона тоже справится с такой функцией, поскольку это синтез первых двух методов.
\end{enumerate}
Все программы имеют критерии останова, которые подразумевают, что мы приблизились к минимуму, с достаточной точностью. Однако на деле это не всегда так. Ниже перечислены случаи, когда это утверждение ложно:
\begin{enumerate}
    \item Достижения требуемой окрестности минимума. То есть условия выхода слишком лояльные.
    \item Достигнут локальный минимум. Чтобы избавиться от этого достаточно примерно знать окрестность глобального минимума или повторить процедуру с другой начальной точкой.
    \item Алгоритм толчется на одном месте.
\end{enumerate}

 Однако существуют функции (поверхности) об которые сломается любой из этих алгоритмов. Достаточно посмотреть на рисунки \ref{fig:Bad_surfaces}. Их общая проблема заключается в том, что большая часть функции является просто плоскостью, поэтому здесь алгоритмы минимизации будут бесполезны - программа не сдвинется с места. Однако используя методы Монте-Карло можно <<бросать точку>> по всей поверхности много раз и определить окрестность, в которой функция отлична от константы. В левом рисунке проблема также заключается в том, что в фактическом минимуме функции не существует производной, поэтому рано или поздно двигаясь к минимуму алгоритм сломается.
 \input{Pictures/Bad_surfaces}
 %Ниже приведу рисунки
 
 \textit{Для экономии вычислительных мощностей и времени работы алгоритмов в физике принято ограничивать значения переменных и функции, в пределах которых ищется минимум.}