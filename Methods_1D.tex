\chapter{Методы поиска (одномерные задачи)}
\section{Основные определения}
Дадим определения некоторым терминам, используемым в данной главе.

\textbf{Эксперимент} - фиксация входной переменной \vx { } с последующей фиксацией результата $y$.

\textbf{Стратегия эксперимента} - Задание набора $\{\vec{x}\}$.

\textbf{Задача поиска} - задача по нахождению $y_{max}$.
Задачи поиска могут быть нескольких типов:
\bi
\item Одномерная задача.
\item \vx { } и $y$ неслучайные величины. Задача детерминирована и стационарна, то есть <<Черный ящик>> всегда одинаково реагирует на один и тот же набор переменных.
\item Стохастическая аппроксимация - \vx { } и $y$ всегда случайные величины.
\ei

Мы же будем заниматься исключительно детерминированными задачами. В данной главе речь идет об одномерных задачах для функций на конечном интервале. Очевидно любой конечный интервал может быть сведен в интервалу $[0, 1]$ простым рефакторингом или смещением аргумента функции, поэтому для простоты далее будем рассматривать именно единичный интервал.

Следует сказать, что методы, рассматриваемые в данной главе работают только с \textit{унимодальными} функциями. Если не внедряться в математические определения, то унимодальная функция представляет собой гладкую на интервале $[0, 1]$ функцию, такую что ее значения в точках, которые ближе к точке максимума (минимума) больше (меньше), чем значения значения в более дальних точках. Примеры унимодальных (a,b) и неунимодальных (c, d) функций изображены на рисунке \ref{fig:unimodal}.
\input{Pictures/unimodal}
Существует два вида поиска:

\textbf{Пассивный} - эксперименты назначаются все сразу, независимо от результатов походу исследования.

\textbf{Последовательный} - Каждый следующий эксперимент назначается в зависимости от предыдущего результата.

Пассивный поиск не так интересен, как последовательный, поэтому рассмотрим его в первую очередь.
\section{Измерение эффективности пассивного поиска}
Перед проведением эксперимента необходимо быть уверенным в том, что:
\bi
\item Функция унимодальна
\item Функция имеет точку экстремума
\ei
Интервал неопределенности максимума в начале эксперимента $[0,1]$ то есть максимум может находиться в любой точке на данном интервале. 
В общем случае, после $n$ экспериментов можно сказать, что $x_{k-1} < x^* < x_{k+1}$, где $x^*$ и есть точка экстремума. Эта область называется \textit{интервалом неопределенности}. Путем многократного проведения эксперимента мы сокращаем интервал неопределенности, а его длина становится равной:
\be
l_n = x_{k+1} - x_{k-1}
\ee
Самой эффективной стратегией считается та, у которой наименьшее $l_n$. И это, вообще говоря, касается не только пассивного поиска.

Рассмотрим пассивную стратегию на примере рисунка \ref{fig:ex1}.
\input{Pictures/ex1}
Здесь множество $x=\{0.2; 0.5; 0.8\}$. Тогда:
\begin{align*} l^{(a)}_3  & {} = [0;x_2]   & L^{(a)}_3 = 0.5 \\  
               l^{(b)}_3  & {} = [x_1;x_3] & L^{(b)}_3 = 0.6 \\
               l^{(c)}_3  & {} = [x_2;1]   & L^{(c)}_3 = 0.5 \end{align*} 

Видим, что наилучшим образом эта стратегия показывает себя в случаях a и c. Эффективность стратегии определяется максимальным интервалом неопределенности $L_n$:
\be
L_n = \max_{1 \leqslant k \leqslant n}{l_n(x_k)}
\ee
Та стратегия лучше, максимальный интервал неопределенности которой меньше. Поскольку стратегия определяется для любых унимодальных функций, то эффективность определяется именно для стратегии, не зависимо от исследуемой функции. Этот принцип называется принципом \textit{минимакса}.
\section*{Вопрос}
Предложите наилучшую стратегию, имея в запасе всего два эксперимента.
\section*{Ответ}
Так как наилучшая стратегия определяется минимально возможным максимальным интервалом неопределенности, то, очевидно, нужно подобрать эксперименты так, чтобы это условие выполнялось. Так как мы располагаем всего двумя экспериментами, то можем получить всего два интервала неопределенности с условием $x_1<x_2$: $[0; x_2]$ и $[x_1; 1]$
Очевидно, что длины интервалов будут тем меньше, чем ближе к центру находятся точки $x_1$ и $x_2$, а значит ответ см. рисунок \ref{fig:q1}:
\begin{align*}l_2 & {}= [0; 0.5 + \frac{\varepsilon}{2}]  & L_2 & {}= 0.5+ \frac{\varepsilon}{2}\\
              l_2 & {}= [0.5 + \frac{\varepsilon}{2} ; 1] & L_2 & {}= 0.5+ \frac{\varepsilon}{2}\end{align*}
\input{Pictures/q1}
\section{Последовательный поиск. Метод дихотомии}
Иллюстрация метода представлена на рисунке \ref{fig:dychotomy}.
\input{Pictures/dichotomy}
Первый эксперимент проводится максимально близко к центру. Второй проводится на абсциссе симметричной относительно первому эксперименту так, чтобы шаг между ними равнялся минимально возможному шагу $\varepsilon$. После этого берется полученный интервал неопределенности (на рис. \ref{fig:dychotomy} для определенности это интервал $[x_1; 1]$) и, аналогично, проводятся 2 эксперимента как можно ближе друг к другу симметрично относительно центра. Далее, очевидно, происходит то же самое.

Таким образом после $n$ экспериментов длина интервала неопределенности составляет:
\be
L_n = 2 ^{-\frac{n}{2}} + \left(1 - 2 ^{-\frac{n}{2}}\right)\varepsilon
\ee

Критерием остановки работы метода является неравенство $L_k \leqslant \varepsilon_0$, где $k$ - номер шага, а $\varepsilon_0$ задаваемая пользователем точность. Такой критерий останова работает для всех последующих методов последовательного поиска, описанных в этой главе. 

Для того, что бы найти максимум с точностью $1\%$ для последовательного поиска необходимо 14 экспериментов, в то время как для пассивного целых 198! 

Приведем последовательный алгоритм метода дихотомии:
\begin{enumerate}
    \item Интервал неопределенности $l_0 = l_1 = [0;1]$. Провести два эксперимента $x_1$ и $x_2$ симметрично относительно центра как можно ближе к друг другу.
    \item Если $f(x_1) < f(x_2)$ сократить интервал неопределенности до $l_2 = [x_1; 1]$. Иначе сократить до интервала $l_2 = [0; x_2]$.
    \item Проверить, является ли длина нового интервала приемлемой (по нашим оценкам). Если да, то остановить программу и принять за максимум абсциссу эксперимента с максимальным значением. Если нет, повторять предыдущие шаги до тех пор, пока не будет выполнено условие $l_k \leqslant \varepsilon_0$.
\end{enumerate}

\section{Метод Фибоначчи}

Один из главных минусов метода дихотомии заключается в том, что при последующих шагах мы не учитываем наличие одного уже проведенного эксперимента. Таким образом мы теряем информацию, которая могла бы использоваться по назначению. С этим хорошо справляется метод Фибоначчи и метод Золотого сечения, речь о котором пойдет в следующем разделе. 

В отличие от метода дихотомии в методе Фибоначчи необходимо заранее задавать количество проводимых экспериментов, а абсцисса первого эксперимента задается формулой:
\be
L_2 = \frac{F_{n-2}}{F_n} + \frac{(-1)^n}{F_n}\varepsilon
\label{Fibonachi}
\ee
Где $F_k$ - числа Фибоначчи, которые задаются рекуррентными соотношениями:
\begin{align*}F_0 & {}= F_1 = 1 \\
F_k & {}= F_{k-1} + F_{k-2}\end{align*}
В остальном метод повторяет уже описанную выше дихотомию, поэтому можем сразу привести алгоритм (см. рис. \ref{fig:Fibonachi}):
\input{Pictures/Fibonachi}
\begin{enumerate}
    \item Интервал неопределенности $l_0 = l_1 = [0;1]$. Задаем число экспериментов $n$.
    \item Ставим первый эксперимент с координатой, вычисленной по формуле (\ref{Fibonachi}).
    \item Ставим эксперимент с координатой, симметричной эксперименту, уже содержащемуся в этом интервале относительно центра интервала неопределенности.
    \item Для нового интервала неопределенности повторяем предыдущий шаг, пока не будет совершено все $n$ экспериментов.
\end{enumerate}

Конeчный интервал неопределенности для $n$ экспериментов будет иметь длину:
\be
L_n = \frac1{F_n} +  \frac{F_{n-2}}{F_n}\varepsilon
\ee

\section{Метод Золотого сечения}

Недостатком метода Фибоначчи является необходимость заранее знать количество экспериментов, которые мы будем проводить. Кроме того, хотелось бы пользоваться таким методом, скорость уменьшения длины интервала неопределенности которого была постоянна. Таким методом и является метод Золотого сечения. Его скорость постоянна и равна $\tau$:
\begin{equation*}
    \frac{L_1}{L_0} = \ldots = \frac{L_{k}}{L_{k+1}} = \tau = 1.61 \ldots
\end{equation*}
Все его отличие от метода Фибоначчи заключается только в выборе начальной точки. Она выбирается с абсциссой $x_1 = \frac1{1+\tau}$, так как именно в этой точке начальный интервал неопределенности делится на две части в золотом соотношении. Дальнейшие действия аналогичны алгоритму метода Фибоначчи, поэтому здесь описаны не будут. Единственное, что стоит сказать, то что критерий останова здесь аналогичен методу дихотомии, поскольку в методе ЗС не ограничено число экспериментов.

Несмотря на замечательность этого метода, все же он уступает методу Фибоначчи, поскольку конечная длина интервала неопределенности после проведения одного и того же числа экспериментов превышает конечную длину интервала неопределенности метода Фибоначчи:
\begin{equation*}
    \frac{L_n^{G}}{L_n^{Fib}} = 1.17.
\end{equation*}
Конечная длина интервала неопределенности для метода Золотого сечения после $n$ экспериментов составляет:
\begin{equation}
    L_n = \frac1{\tau^{n-1}}
\end{equation}
\section{Метод Дэвиса, Свенна, Кемпи}
Условимся, что в этом разделе будем искать минимум унимодальной функции, хотя, в принципе, понятно, что таким же образом можно искать и максимум, а алгоритм фактически не будет отличаться. Единственным условием для совершения процедуры, описываемой далее, является необходимость того, чтобы \textbf{первый эксперимент был левее точки экстремума}, так, чтобы наши шаги приводили нас от точки первого эксперимента к экстремуму. Рекомендуется разбирать алгоритм обращая внимание на рисунок \ref{fig:Davis}, иллюстрирующий все шаги данного метода.

Итак начнем:
\begin{enumerate}
    \item Проводим эксперимент $x_0$.
    \item Далее по направлению оси $x$ отступаем на величину $\Delta x$ и делаем эксперимент $x_1$.
    \item Видим, что в данной точке $f(x_1) < f(x_0)$, значит нужно повторить предыдущий пункт, увеличив величину шага вдвое.
    \item Таким образом проводится эксперимент $x_2$ на расстоянии $2 \Delta x$ от $x_1$. Видим, что $f(x_2) < f(x_1)$. Опять проводим эксперимент $x_3$ теперь уже на расстоянии $4 \Delta x$ от $x_2$, и снова наблюдаем, что $f(x_3) < f(x_2)$.
    \item Выполняем эту процедуру снова, отступая от $x_3$ на расстояние $8 \Delta x$ проводим эксперимент $x_4$. И тут видим, что $f(x_4) > f(x_3)$. Значит точка минимума где-то в интервале $[x_2; x_4]$.
    \item Делим этот интервал пополам и на середине проводим эксперимент $x_{mid}$.
    \item Далее сравниваем значения функций в последних четырех точках и отбрасываем точку в которой функция принимает максимальное значение. В нашем случае $f(x_4) > f(x_2) > f(x_{mid}) > f(x_3)  $, поэтому отбрасывается точка $x_4$ (она выделена красным цветом).
    \item Через оставшиеся три точки проводится парабола и уже по ее аналитическому виду находится минимум исследуемой функции (парабола синяя на рисунке, как и результирующая точка минимума).
\end{enumerate}

Вполне понятно, что на этапе поиска интервала, где содержится минимум может быть от двух до сколь угодно много экспериментов. Однако в конце мы будем работать с однозначной параболой по последним четырем точкам, одну из которых отбросим. Правда данный метод требует модификации для возможного улучшения точности нахождения минимуму, о чем пойдет речь в следующем разделе.
\section{Метод Пауэлла}
Алгоритм данного метода практически идентичен предыдущему. Отличие заключается в том, что после того, как была отброшена точка (пункт 7) и построена парабола (пункт 8), по которой был найден минимум, в этом минимуме проводится эксперимент (точка $x^*$ на рис \ref{fig:Davis}). Далее берутся значения функции в точках, через которые была проведена парабола только что измеренная точка, после чего с ними проводится такая же процедура, как и в пункте 7 предыдущего раздела. То есть в нашем случае $f(x_2) > f(x_{mid}) > f(x_3) > f(x^*)$. Аналогично отбрасывается та точка, в которой значение функции максимально. Затем эти действия повторяются вновь, тем самым увеличивая точность нахождения минимума.

Критерием останова данного метода является величина:
\begin{equation}
    \frac{^{(k)}x_{min} - ^{(k-1)}x_{min}}{^{(k)}x_{min}} \sim \varepsilon_0
\end{equation}
Где $\varepsilon_0$ мы выбираем самостоятельно.
\input{Pictures/Davis}